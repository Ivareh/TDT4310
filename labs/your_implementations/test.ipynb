{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f7d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ceb2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "document1 = \"I love cats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0423ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "document2 = \"I love dogs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05bcd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document3 = \"I love cats, but I also like dogs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "625d7ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'cats', ',', 'but', 'I', 'also', 'like', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "tokenize = nltk.word_tokenize(document3)\n",
    "print(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9229def",
   "metadata": {},
   "outputs": [],
   "source": [
    "FD = nltk.FreqDist(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d4dc0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 0.125, 'like': 0.125}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF = {\"love\": 0, \"like\": 0}\n",
    "for value, count in FD.items():\n",
    "    if(value == \"like\"):\n",
    "        TF[\"like\"] = count / len(FD)\n",
    "    if(value == \"love\"):\n",
    "        TF[\"love\"] = count / len(FD)\n",
    "TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0af0609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I love cats', 'I love dogs', 'I love cats, but I also like dogs')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'love': 1.0, 'like': 3.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDF = {\"love\": 0, \"like\": 0}\n",
    "\n",
    "alldocs = document1,document2,document3\n",
    "print(alldocs)\n",
    "countterms = {\"love\": 0, \"like\": 0}\n",
    "for doc in alldocs:\n",
    "    for word in doc.split():\n",
    "        if word == \"love\":\n",
    "            countterms[\"love\"] = countterms[\"love\"] + 1\n",
    "        if word == \"like\":\n",
    "            countterms[\"like\"] = countterms[\"like\"] + 1\n",
    "            \n",
    "IDF[\"love\"] = len(alldocs) / countterms[\"love\"]\n",
    "IDF[\"like\"] = len(alldocs) / countterms[\"like\"]\n",
    "\n",
    "IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa1a14a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "love\n",
      "like\n",
      "like\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'love': 0.125, 'like': 0.375}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = {\"love\": 0, \"like\": 0}\n",
    "for (word1, score1), (word2, score2) in zip(TF.items(), IDF.items()):\n",
    "    print(word1)\n",
    "    print(word2)\n",
    "    tf_idf[word1] = float(score1 * score2)\n",
    "\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60e26367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 0.07592502839365867,\n",
       " 'love': 0.046680152755974216,\n",
       " 'cats,': 0.07997143423076541,\n",
       " 'but': 0.07997143423076541,\n",
       " 'also': 0.07997143423076541,\n",
       " 'like': 0.07997143423076541,\n",
       " 'dogs': 0.058966974213797374}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldocs2 = document1 +\" \" + document2 + \" \" + document3\n",
    "docsplit = alldocs2.split()\n",
    "\n",
    "nltk_textcollection = TextCollection(docsplit)\n",
    "\n",
    "\n",
    "\n",
    "unseen_sent = \"I love cats, but I also like dogs\"\n",
    "# produce all tf_idf scores for the given sentence\n",
    "tf_vector = {}\n",
    "for word in unseen_sent.split():\n",
    "    tf_vector[word] = (nltk_textcollection.tf_idf(word, unseen_sent))\n",
    "tf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7cfcce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import UnigramTagger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35c6c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c7ee021",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"I saw her duck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ba4c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = brown.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb635b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = brown.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97416ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag1 = DefaultTagger('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f824e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2 = UnigramTagger(train_data, backoff = tag1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18fead02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I -> PPSS\n",
      "saw -> VBD\n",
      "her -> PP$\n",
      "duck -> VB\n"
     ]
    }
   ],
   "source": [
    "for word, tag in tag2.tag(sent.split()):\n",
    "...     print(word, '->', tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0bc57e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "30c868e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84061f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I saw her duck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c9046aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I saw her duck"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "68d42b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     POS    TAG    Dep    POS explained        tag explained \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'text':{8}} {'POS':{6}} {'TAG':{6}} {'Dep':{6}} {'POS explained':{20}} {'tag explained'} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "25ccb7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I        PRON   PRP    nsubj  pronoun              pronoun, personal\n",
      "saw      VERB   VBD    ROOT   verb                 verb, past tense\n",
      "her      PRON   PRP$   poss   pronoun              pronoun, possessive\n",
      "duck     NOUN   NN     dobj   noun                 noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.text:{8}} {token.pos_:{6}} {token.tag_:{6}} {token.dep_:{6}} {spacy.explain(token.pos_):{20}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c21dca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = nltk.corpus.brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1817d498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f30005d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "corpus = nltk.corpus.brown.sents()\n",
    "def preprocess(sent):\n",
    "    sent = \" \".join(sent)\n",
    "    return sent.strip()\n",
    "corpus = [preprocess(sent) for sent in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a54ebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\",\n",
       " \"The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted .\",\n",
       " \"The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr. .\",\n",
       " \"`` Only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' .\",\n",
       " \"The jury said it did find that many of Georgia's registration and election laws `` are outmoded or inadequate and often ambiguous '' .\"]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "499a5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = [], []\n",
    "start_words = []\n",
    "for doc in nlp.pipe(corpus, batch_size=1000):\n",
    "    _words, _tags = zip(*[(t.text, t.pos_) for t in doc])\n",
    "    start_words.append(_words[0])\n",
    "    # _words = [w.lower() for w in _words if w.isalnum()]\n",
    "    words.extend(_words)\n",
    "    tags.extend(_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4cc58cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'tag_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sent\u001b[38;5;241m.\u001b[39msplit():\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag_\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'tag_'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb9e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0ba2138ccdeef291c4f3939fc0ec3da14a9e1624c959932cf0ad354e60d5648"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
